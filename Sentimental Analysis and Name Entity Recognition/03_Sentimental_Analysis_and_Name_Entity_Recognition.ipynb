{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentimental_Analysis_and_Name_Entity_Recognition"
      ],
      "metadata": {
        "id": "EcbEliwmmivk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aim  \n",
        "To perform sentimental analysis on text data using pre-trained models and to implement named entity recognition(NER) for extracting entities such as Person, Organizationand Location using NLP libraries lick Spacy"
      ],
      "metadata": {
        "id": "LSzDQMszbqNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_4QSH0hScLXa",
        "outputId": "df022868-36c8-44ea-f904-bea95aac05e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sentiment Analysis**\n",
        "\n",
        "Sentiment Analysis is an NLP technique used to determine the emotional tone of a text. It helps identify whether a sentence expresses a positive, negative, or neutral opinion.\n",
        "\n",
        "It is widely used in:\n",
        "\n",
        "* Movie and product reviews\n",
        "\n",
        "* Social media analysis\n",
        "\n",
        "* Customer feedback systems"
      ],
      "metadata": {
        "id": "oZg-y7MelZ4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "sentences =[\n",
        "    \"The Movie was Fantastic\",\n",
        "    \"The Plot was Boring\",\n",
        "    \"The music was Average\",\n",
        "    \"I Would not recommend this Film\",\n",
        "    \"The acting was Excellent\"\n",
        "]\n",
        "\n",
        "polarities =[]\n",
        "\n",
        "for sentence in sentences:\n",
        "  blob = TextBlob(sentence)\n",
        "  polarity = blob.sentiment.polarity\n",
        "  polarities.append(polarity)\n",
        "\n",
        "  if polarity > 0:\n",
        "    sentiment = \"Positive\"\n",
        "  elif polarity <0:\n",
        "    sentiment = \"Negative\"\n",
        "  else:\n",
        "    sentiment = \"Neutral\"\n",
        "\n",
        "  print(sentence)\n",
        "  print(\"polarity:\",polarity, \"sentiment:\",sentiment)\n",
        "  print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyzgJjU8cspK",
        "outputId": "81bec7e7-a929-4e6c-bb9b-1823ea6a21d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Movie was Fantastic\n",
            "polarity: 0.4 sentiment: Positive\n",
            "\n",
            "The Plot was Boring\n",
            "polarity: -1.0 sentiment: Negative\n",
            "\n",
            "The music was Average\n",
            "polarity: -0.15 sentiment: Negative\n",
            "\n",
            "I Would not recommend this Film\n",
            "polarity: 0.0 sentiment: Neutral\n",
            "\n",
            "The acting was Excellent\n",
            "polarity: 0.5 sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### **Named Entity Recognition (NER)**\n",
        "\n",
        "Named Entity Recognition is an NLP task that identifies and classifies real-world entities in text.\n",
        "\n",
        "Common entity types include:\n",
        "\n",
        "* PERSON -> names of people\n",
        "\n",
        "* ORG -> organizations\n",
        "\n",
        "* GPE / LOC -> locations\n",
        "\n",
        "\n",
        "#### **Applications of NER**\n",
        "\n",
        "Named Entity Recognition is used in:\n",
        "\n",
        "* Information extraction\n",
        "\n",
        "* Resume parsing\n",
        "\n",
        "* News analysis\n",
        "\n",
        "* Question-answering systems"
      ],
      "metadata": {
        "id": "6y5o4um6ljrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Elon Musk is the CEO of Tesla and SpaceX based in the US\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "   print(ent.text, \"->\" ,ent.label_)\n",
        "\n",
        "entity_count = {}\n",
        "\n",
        "for ent in doc.ents:\n",
        "  entity_count[ent.label_] = entity_count.get(ent.label_,0)+1\n",
        "\n",
        "print(\"ENtity Count: \"),entity_count\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5how2NbdVBL",
        "outputId": "79c3da59-0375-494a-a7a6-c0616d8362ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk -> PERSON\n",
            "Tesla -> ORG\n",
            "SpaceX -> PERSON\n",
            "US -> GPE\n",
            "ENtity Count: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, {'PERSON': 2, 'ORG': 1, 'GPE': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}